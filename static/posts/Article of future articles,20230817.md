---
title: Article of future articles!
created: 17 August 2023
---

I think it's traditional that all blogs have a post about them wanting to most more. 

Continuing that spirit, here are some posts I'd like to write, covering some of my favourite topics from my course at UCL

* Why is the negative gradient used in gradient descent? (in progress [here](https://github.com/bndxn/ml-mechanics))
* What is the probabilistic approach? 
* What is a generative approach?
* Explain L1 and L2 regularisation
* What is the kernel trick?
* Give an example of a Bayesian regression and pros and cons against non-probabilistic method
* What is the Halting problem, and what are its implications?

**Longer-term**

* What are the trends in LLMs, and how capable are they?
